# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nViyuIQQtkD_QNXDioBsh20IERxYyDfC
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import torch.nn as nn
from transformers import DistilBertTokenizer, DistilBertModel
import numpy as np
import json
import os
import requests
import sys

app = Flask(__name__)
CORS(app)

# Configuration paths
MODEL_DIR = "model"
MODEL_PATH = os.path.join(MODEL_DIR, "best_model.pt")
THRESHOLDS_PATH = os.path.join(MODEL_DIR, "best_thresholds.npy")
CONFIG_PATH = os.path.join(MODEL_DIR, "config.json")

# GitHub release URL for large model file
MODEL_URL = "https://github.com/ChiNguyen-git/mindbridge-model-api/releases/download/v1.0/best_model.pt"

# Device configuration
device = torch.device('cpu')

# Ensure model folder exists
os.makedirs(MODEL_DIR, exist_ok=True)

# Default configuration
CONFIG = {
    "dropout": 0.3,
    "model_name": "distilbert-base-uncased",
    "thresholds": {
        "depression": 0.27,  # actual threshold
        "ptsd": 0.29         # actual threshold
    },
    "tiers": {
        "chatbot_tiers": {
            "depression": {
                "minimal": [0, 0.27],
                "mild": [0.27, 0.4],
                "moderate": [0.4, 0.74],
                "moderate_severe": [0.74, 0.93],
                "severe": [0.93, 1.0]
            },
            "ptsd": {
                "minimal": [0, 0.29],
                "mild": [0.29, 0.54],
                "moderate": [0.54, 0.86],
                "severe": [0.86, 1.0]
            }
        }
    }
}

# Load config.json if exists
if os.path.exists(CONFIG_PATH):
    try:
        with open(CONFIG_PATH, 'r') as f:
            loaded_config = json.load(f)
            CONFIG.update(loaded_config)
        print("‚úÖ Config loaded from file")
    except Exception as e:
        print(f"‚ö†Ô∏è Using default config: {e}")

# Load thresholds from .npy file if exists
if os.path.exists(THRESHOLDS_PATH):
    try:
        thresholds = np.load(THRESHOLDS_PATH, allow_pickle=True)
        if isinstance(thresholds, np.ndarray) and len(thresholds) >= 2:
            CONFIG['thresholds']['depression'] = float(thresholds[0])
            CONFIG['thresholds']['ptsd'] = float(thresholds[1])
            print(f"‚úÖ Loaded thresholds from file - Depression: {CONFIG['thresholds']['depression']:.3f}, PTSD: {CONFIG['thresholds']['ptsd']:.3f}")
        elif isinstance(thresholds, dict):
            CONFIG['thresholds'].update(thresholds)
            print(f"‚úÖ Loaded thresholds from dict")
    except Exception as e:
        print(f"‚ö†Ô∏è Using default thresholds: {e}")
else:
    print(f"‚ÑπÔ∏è Using hardcoded thresholds - Depression: {CONFIG['thresholds']['depression']}, PTSD: {CONFIG['thresholds']['ptsd']}")

# Download model if missing
if not os.path.exists(MODEL_PATH):
    print("üîΩ Downloading model file from GitHub Release...")
    print(f"   URL: {MODEL_URL}")
    try:
        response = requests.get(MODEL_URL, stream=True)
        if response.status_code == 200:
            total_size = int(response.headers.get('content-length', 0))
            with open(MODEL_PATH, 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"   Progress: {percent:.1f}%", end='\r')
            print("\n‚úÖ Model downloaded successfully!")
        else:
            print(f"‚ùå Failed to download model: HTTP {response.status_code}")
            sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error downloading model: {e}")
        sys.exit(1)
else:
    print("‚úÖ Model file found locally")

# Define Model Architecture
class DepressionPTSDModel(nn.Module):
    def __init__(self, dropout=0.3):
        super(DepressionPTSDModel, self).__init__()
        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(768, 2)  # 2 outputs: depression, ptsd
        self.sigmoid = nn.Sigmoid()

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        return self.sigmoid(logits)

# Load Model (REQUIRED - exits if fails)
print("üì¶ Loading model architecture...")
try:
    # Create model instance
    model = DepressionPTSDModel(dropout=CONFIG.get('dropout', 0.3))

    print(f"üì¶ Loading model weights from: {MODEL_PATH}")
    # Load the checkpoint
    checkpoint = torch.load(MODEL_PATH, map_location=device)

    # Handle different checkpoint formats
    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
    else:
        # It's already a state_dict (OrderedDict)
        state_dict = checkpoint

    # Load weights into model
    model.load_state_dict(state_dict, strict=False)

    # Set to evaluation mode
    model.eval()

    # Disable gradient computation
    for param in model.parameters():
        param.requires_grad = False

    print("‚úÖ Model loaded and ready!")

except Exception as e:
    print(f"‚ùå CRITICAL: Failed to load model: {e}")
    print("Cannot start server without model")
    sys.exit(1)

# Load tokenizer
print("üì¶ Loading tokenizer...")
try:
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
    print("‚úÖ Tokenizer loaded!")
except Exception as e:
    print(f"‚ùå CRITICAL: Failed to load tokenizer: {e}")
    sys.exit(1)

def get_depression_level(prob, threshold=0.27):
    """Determine depression severity level based on probability"""
    if prob < threshold:
        return 'minimal', 0
    elif prob < 0.4:
        return 'mild', 1
    elif prob < 0.74:
        return 'moderate', 2
    elif prob < 0.93:
        return 'moderate-severe', 3
    else:
        return 'severe', 4

def get_ptsd_level(prob, threshold=0.29):
    """Determine PTSD severity level based on probability"""
    if prob < threshold:
        return 'minimal', 0
    elif prob < 0.54:
        return 'mild', 1
    elif prob < 0.86:
        return 'moderate', 2
    else:
        return 'severe', 3

def estimate_phq8_score(depression_prob, depression_positive):
    """Convert depression probability to estimated PHQ-8 score (0-24)"""
    if not depression_positive:
        # Not depressed: 0-4
        return int(depression_prob * 15)
    elif depression_prob < 0.4:
        # Mild: 5-9
        return 5 + int((depression_prob - 0.27) * 31)
    elif depression_prob < 0.74:
        # Moderate: 10-14
        return 10 + int((depression_prob - 0.4) * 15)
    elif depression_prob < 0.93:
        # Moderate-severe: 15-19
        return 15 + int((depression_prob - 0.74) * 26)
    else:
        # Severe: 20-24
        return 20 + int((depression_prob - 0.93) * 57)

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'model': 'DistilBERT Depression/PTSD Detector',
        'thresholds': CONFIG['thresholds'],
        'model_loaded': True
    })

@app.route('/analyze', methods=['POST'])
def analyze():
    """Main analysis endpoint"""
    try:
        data = request.json
        text = data.get('transcript', '')

        if not text or not text.strip():
            return jsonify({'error': 'No text provided'}), 400

        # Tokenize input text
        inputs = tokenizer(
            text,
            return_tensors='pt',
            truncation=True,
            padding=True,
            max_length=512
        )

        # Get model predictions
        with torch.no_grad():
            outputs = model(inputs['input_ids'], inputs['attention_mask'])
            probs = outputs.cpu().numpy()[0]

        # Extract probabilities
        depression_prob = float(probs[0])
        ptsd_prob = float(probs[1])

        # Binary classification based on thresholds
        depression_threshold = CONFIG['thresholds']['depression']
        ptsd_threshold = CONFIG['thresholds']['ptsd']

        depression_positive = depression_prob >= depression_threshold
        ptsd_positive = ptsd_prob >= ptsd_threshold

        # Get severity levels
        depression_level, depression_severity = get_depression_level(depression_prob, depression_threshold)
        ptsd_level, ptsd_severity = get_ptsd_level(ptsd_prob, ptsd_threshold)

        # Estimate PHQ-8 score
        phq8_score = estimate_phq8_score(depression_prob, depression_positive)
        phq8_score = min(max(phq8_score, 0), 24)  # Ensure 0-24 range

        # Determine if intervention needed
        needs_intervention = (
            (depression_positive and depression_severity >= 2) or  # Moderate or higher
            (ptsd_positive and ptsd_severity >= 2)  # Moderate or higher
        )

        # Calculate confidence (distance from threshold)
        depression_confidence = abs(depression_prob - depression_threshold)
        ptsd_confidence = abs(ptsd_prob - ptsd_threshold)
        overall_confidence = (depression_confidence + ptsd_confidence) / 2

        # Prepare response
        response = {
            # Raw probabilities
            'depression_probability': depression_prob,
            'ptsd_probability': ptsd_prob,

            # Binary detection
            'depression_detected': depression_positive,
            'ptsd_detected': ptsd_positive,

            # Severity levels
            'depression_level': depression_level,
            'ptsd_level': ptsd_level,

            # PHQ-8 estimation
            'phq8_score': phq8_score,

            # Intervention recommendation
            'needs_intervention': needs_intervention,

            # Confidence metrics
            'confidence': overall_confidence,
            'depression_confidence': depression_confidence,
            'ptsd_confidence': ptsd_confidence,

            # Thresholds used
            'thresholds_used': {
                'depression': depression_threshold,
                'ptsd': ptsd_threshold
            }
        }

        return jsonify(response)

    except Exception as e:
        print(f"Error in analyze: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': str(e),
            'type': 'analysis_error'
        }), 500

@app.route('/test', methods=['GET'])
def test():
    """Test endpoint with sample texts"""
    test_cases = [
        "I feel great and happy today",
        "I'm a bit stressed about work",
        "I feel very sad and hopeless, I can't sleep"
    ]

    results = []
    for text in test_cases:
        # Get prediction for each test case
        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs = model(inputs['input_ids'], inputs['attention_mask'])
            probs = outputs.cpu().numpy()[0]

        dep_prob = float(probs[0])
        ptsd_prob = float(probs[1])

        results.append({
            'text': text[:50],
            'depression': {
                'probability': dep_prob,
                'detected': dep_prob >= CONFIG['thresholds']['depression'],
                'level': get_depression_level(dep_prob)[0]
            },
            'ptsd': {
                'probability': ptsd_prob,
                'detected': ptsd_prob >= CONFIG['thresholds']['ptsd'],
                'level': get_ptsd_level(ptsd_prob)[0]
            }
        })

    return jsonify({
        'thresholds': CONFIG['thresholds'],
        'test_results': results
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    print("="*50)
    print(f"üöÄ Starting MindBridge Model API")
    print(f"üìç Port: {port}")
    print(f"üéØ Thresholds - Depression: {CONFIG['thresholds']['depression']}, PTSD: {CONFIG['thresholds']['ptsd']}")
    print(f"‚úÖ Model: Loaded and ready")
    print("="*50)
    app.run(host='0.0.0.0', port=port, debug=False)